{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a311bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc22555144354b2785003332e9275a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\q-9ite\\q9\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45261279a4b45a1a5230be38c996765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"sd-legacy/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"A single stylized low-poly fantasy treasure chest, centered and isolated on a pure white background, no shadows, no reflections, no ground. Clean edges, simple textures, evenly lit, perfect for 3D reconstruction.\"\n",
    "image = pipe(prompt).images[0]  \n",
    "    \n",
    "image.save(\"treasure_chest1.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1627a457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True (device 0)\n",
      "Name: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Capability: (8, 9)\n",
      "Memory: 5.32 GB free / 6.44 GB total\n"
     ]
    }
   ],
   "source": [
    "# Quick GPU availability + memory check\n",
    "import torch\n",
    "\n",
    "def describe_cuda():\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA available: False\")\n",
    "        return\n",
    "    device = torch.device(\"cuda\")\n",
    "    idx = device.index or 0\n",
    "    print(f\"CUDA available: True (device {idx})\")\n",
    "    print(f\"Name: {torch.cuda.get_device_name(idx)}\")\n",
    "    print(f\"Capability: {torch.cuda.get_device_capability(idx)}\")\n",
    "    free, total = torch.cuda.mem_get_info(idx)\n",
    "    print(f\"Memory: {free/1e9:.2f} GB free / {total/1e9:.2f} GB total\")\n",
    "\n",
    "describe_cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb7b0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "q9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
